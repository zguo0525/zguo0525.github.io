---
layout: default
title: "Jumping from Apple to Meta: When Everything Changed"
description: "What I learned from Apple's pivot away from AI and why I joined Meta's Superintelligence Labs. Insights on building AI products at scale, organizational culture, and making career transitions in fast-moving industries."
date: 2025-12-31
tags: [Apple, Meta, MSL, career, AI, product, research, transition, reflection, leadership, strategy]
---

# Jumping from Apple to Meta: When Everything Changed

In June 2025, Apple published a research paper titled ["The Illusion of Thinking"](https://machinelearning.apple.com/research/illusion-of-thinking). The paper critically examined reasoning models, suggesting that AI systems rely more on pattern matching than genuine reasoning. For me, this publication signaled something deeper: a strategic shift away from aggressive AI investment.

Days later, at WWDC 2025, Apple announced Liquid Glass—a major iOS redesign. The headline feature wasn't AI advancement; it was a visual refresh. The market responded with a 1.2% stock decline ([CNBC](https://www.cnbc.com/2025/06/09/apple-wwdc-underwhelms-on-ai-software-biggest-facelift-in-decade-.html)), reflecting investor concerns about Apple's AI positioning.

That's when I realized: everything had changed. I had spent a year at Apple working on Visual Intelligence, shipping features that would reach millions of users. But in that moment, I saw the strategic shift happening in real-time. The company I joined to build AI products was signaling it was moving in a different direction. The question wasn't whether to stay or go—it was whether I wanted to be part of building the future or watching it get built elsewhere.

## The Challenge of Building AI Products at Scale

Building great AI products is fundamentally different from building traditional software. At a company like Apple, it requires rethinking everything: infrastructure, evaluation systems, organizational structure, and cultural norms. You cannot simply bolt AI capabilities onto existing products and expect meaningful results.

I learned this firsthand while working on Visual Intelligence for Apple Intelligence—the on-screen search and smart event creation features that launched at WWDC 2025. We shipped features, but the deeper challenge was organizational: how do you maintain urgency and innovation when a company has been dominant in one domain for over a decade?

Apple's smartphone dominance created a different operating mode. The organization had grown comfortable, and when the AI revolution accelerated, the cultural and structural readiness wasn't there. The response was telling: rather than building AI that works, the company published research questioning whether AI works at all.

## The Competitive Landscape

While Apple was publishing critiques, the AI landscape was accelerating. DeepSeek R1, OpenAI's Gibili, and Gemini Nano Banana were pushing boundaries in reasoning, multimodal understanding, and efficiency. The competition in AI is unforgiving: you either ship something remarkable, or you fall behind.

Even Meta, with FAIR's legendary research history, faced challenges with Llama 4 launches. The field moves too fast for anyone to rest on past achievements. This intensity creates a clear divide: companies that commit fully to AI innovation, and those that don't.

I found myself at a crossroads. I had learned valuable lessons about product integration, privacy constraints, and shipping at scale. I was proud of what we'd built—Visual Intelligence shipped at WWDC 2025, and the on-screen search feature worked well within Apple's constraints. But I also recognized that the environment I was in wasn't positioned to win in the AI race. The signals were clear: when your company publishes papers questioning whether AI works instead of building AI that works, that's not a technical problem—it's a strategic one.

My research background gave me context: I'd seen how fast the field moves from my work at MIT-IBM Watson and from publishing papers like JetMoE and API Pack. My product experience at Apple gave me judgment: I knew what it took to ship, and I could see when an organization wasn't set up to compete. The combination made the decision clear, even if it wasn't easy.

## The Strategic Pivot

Meta's approach was fundamentally different. In 2025, Mark Zuckerberg entered what insiders describe as ["founder's mode"](https://www.bloomberg.com/news/newsletters/2025-06-12/zuckerberg-snaps-back-into-founder-mode-on-ai-for-better-or-worse)—personally spearheading the company's pursuit of AGI and ASI with hands-on involvement that marked a departure from traditional corporate strategies ([Bloomberg](https://www.bloomberg.com/news/newsletters/2025-06-12/zuckerberg-snaps-back-into-founder-mode-on-ai-for-better-or-worse)).

The commitment was visible in concrete actions. Zuckerberg established Meta Superintelligence Labs (MSL) and personally recruited top talent, including Alexandr Wang, founder of Scale AI, and Nat Friedman, former CEO of GitHub ([Bloomberg](https://www.bloomberg.com/news/articles/2025-06-10/zuckerberg-recruits-new-superintelligence-ai-group-at-meta), [CNBC](https://www.cnbc.com/amp/2025/06/30/mark-zuckerberg-creating-meta-superintelligence-labs-read-the-memo.html)). The company offered compensation packages ranging from $200 million to $300 million over four years to elite AI researchers, reflecting the aggressive recruitment strategy needed to build a concentrated group of experts ([AM World Group](https://www.amworldgroup.com/blog/meta-ai-takes-first-step-to-superintelligence)).

Infrastructure investments matched the talent commitment. Meta is constructing massive AI data centers: "Prometheus," a 1-gigawatt facility expected to come online in 2026, and "Hyperion," anticipated to scale up to 5 gigawatts—facilities significantly larger than traditional data centers ([Tom's Hardware](https://www.tomshardware.com/tech-industry/artificial-intelligence/meta-plans-multi-gw-data-center-thats-nearly-the-size-of-manhattan-zuckerberg-promises-enormous-ai-splash-as-company-uses-tents-to-try-and-keep-up-with-rate-of-expansion)). The company is also developing custom silicon through its MTIA program to enhance AI processing capabilities ([Meta Engineering](https://engineering.fb.com/2024/10/15/data-infrastructure/metas-open-ai-hardware-vision/)).

Zuckerberg articulated a vision for ["personal superintelligence"](https://www.tomshardware.com/tech-industry/artificial-intelligence/metas-zuckerberg-outlines-vision-for-personal-superintelligence-in-a-letter-says-that-unlike-rivals-his-approach-isnt-about-automating-everything)—AI designed to augment individual capabilities rather than replace human labor, contrasting with competitors focused on automation ([Tom's Hardware](https://www.tomshardware.com/tech-industry/artificial-intelligence/metas-zuckerberg-outlines-vision-for-personal-superintelligence-in-a-letter-says-that-unlike-rivals-his-approach-isnt-about-automating-everything)). The company is building models from scratch, training next-generation systems like Llama 3, and reorganizing AI teams to align with AGI objectives ([Axios](https://www.axios.com/2024/01/18/zuckerberg-meta-llama-3-ai)).

The message was clear: achieving AGI and ASI is not optional for Meta. This wasn't a side project; it was the company's strategic priority.

I made the decision to join Meta's Superintelligence Labs. It was a calculated risk, but one that aligned with where I believed the industry was heading. The decision wasn't just about the role—it was about joining a team that was building foundational capabilities, not incremental features. At Apple, I'd learned what it takes to ship AI products at scale. At Meta MSL, I'm learning what it takes to push capability frontiers. The combination is what I needed to position myself for where AI is heading.

The culture at Meta GenAI and MSL reflects this commitment. The teams are composed of people who share a sense of urgency, who are driven to make an impact, and who understand the stakes. We're working on problems like multimodal embodiment—fundamental questions about how AI systems understand and interact with the physical world. Coming from Apple where I worked on features that shipped to millions of users, I now understand what it takes to turn research into product. And coming from research where I published papers on efficient architectures, I understand what it takes to push technical boundaries. The combination is what makes this work meaningful.

## What the Transition Taught Me

Moving from Apple's product-focused environment to Meta's research-driven culture revealed insights that I couldn't have learned from either experience alone. Coming from a research background—my PhD at MIT, work at MIT-IBM Watson on synthetic data and code generation, and papers on efficient architectures like JetMoE—I thought I understood the gap between research and product. Working at Apple taught me how much I didn't know.

**1. On-device constraints force creativity, but they also limit ambition.** While working on Visual Intelligence for Apple Intelligence, I learned to optimize for latency, privacy, and token budgets. The on-screen search feature we shipped at WWDC 2025 worked within these constraints, but I also saw how those same constraints prevented us from building the kind of capabilities that DeepSeek R1 or OpenAI's Gibili were creating. At MIT-IBM Watson, I worked on synthetic data generation and model training with fewer constraints—we could experiment more freely. The lesson: constraints teach you optimization, but removing constraints teaches you what's possible.

**2. Integration is harder than capability.** At Apple, I worked on notification summaries—a feature that seemed straightforward but exposed the real challenge: making AI work reliably across edge cases, privacy boundaries, and organizational silos. I wrote about this in my Siri essay: demos wow, but shipping is harder. Coming from research where I published papers on API Pack and AuthentiGPT, I was used to optimizing for benchmarks. At Apple, I learned that benchmarks don't matter if the feature breaks in production or violates privacy constraints. At Meta MSL, I'm back to pushing capability frontiers, but now I understand what it takes to turn capability into product.

**3. Research experience accelerates product work, but product experience clarifies research priorities.** My work on JetMoE—building efficient architectures that reached Llama2 performance with $0.1M—taught me to think about cost and scale. At Apple, that thinking helped me optimize for on-device constraints. But Apple also taught me what users actually need: not just better models, but features that solve real problems. Now at Meta MSL, working on multimodal embodiment, I'm asking research questions informed by product experience: what capabilities will matter when we try to ship this?

**4. The best career moves align with where the industry is heading, not where it is.** I left Apple not because the work was bad—Visual Intelligence shipped, and I'm proud of what we built—but because I saw the strategic shift. When Apple published "The Illusion of Thinking" and announced Liquid Glass instead of AI breakthroughs, I recognized that the company was moving away from aggressive AI investment. Meanwhile, Meta was going all-in. My research background gave me the technical foundation; my product experience at Apple gave me the judgment to recognize the strategic moment. The transition wasn't just about a better role—it was about positioning for where AI is heading.

## What I Learned About Building AI Products

My experience spans research (MIT, MIT-IBM Watson, papers on efficient architectures) and product (Apple's Visual Intelligence, notification summaries). Here's what I learned about what actually works:

**1. You need both capability and integration, but most teams optimize for only one.** At MIT-IBM Watson, I worked on synthetic data generation and model training—pushing capability frontiers. At Apple, I learned integration: how to take a model and make it work reliably in production, within privacy constraints, across organizational boundaries. The teams that win do both: they push capability (like Meta building models from scratch) while also building the integration systems that turn capability into product. Apple had integration expertise but wasn't pushing capability. That's why Visual Intelligence shipped, but it wasn't groundbreaking.

**2. Constraints teach you optimization, but they can also limit your ambition.** Working on JetMoE taught me to optimize for efficiency—reaching Llama2 performance with minimal cost. At Apple, on-device constraints forced similar optimization: how do you make AI work within tight latency and privacy bounds? These constraints are valuable—they teach you to build efficiently. But I also saw how they can become excuses: "we can't do X because of privacy" or "we can't do Y because of on-device limits." The best teams use constraints to force creativity, not to limit ambition. Meta's approach—building infrastructure first, then pushing capability—avoids this trap.

**3. Research experience accelerates product work, but product experience clarifies what research matters.** My papers on API Pack and AuthentiGPT were about pushing technical boundaries. At Apple, I learned which technical boundaries actually matter for users. Notification summaries taught me that tone and context matter more than raw capability—a lesson that now informs my research at Meta MSL on multimodal embodiment. The question isn't "can we build this?" but "should we build this, and will it matter when we try to ship it?"

**4. The gap between research and product is organizational, not technical.** At Apple, I saw how split ownership between research teams (training models) and product teams (shipping features) created delays. The "Intelligent Systems" team trained models; Siri shipped features. The handoff was slow. At Meta MSL, research and product are more integrated—we're building capabilities that will become products, not handing off research to product teams. This alignment matters more than model size or infrastructure investment.

Apple had integration expertise and resources, but lacked the strategic commitment to push capability frontiers. Meta has both—which is why I'm here, and why I believe we can build something that matters.

## The Alpha vs. Beta Play

The transition wasn't easy. Moving from a product-focused culture to a research-driven environment required adapting to different feedback loops, success metrics, and ways of working. But it was also liberating: I'm now working on problems that might not have clear product paths for years, if ever.

More importantly, the transition clarified a fundamental truth about building AI products: if you want to create something great, you need to train your own models and build new capabilities from the ground up. You cannot win by simply adding rewrite or summarization features to existing apps.

The market rewards first-movers who create eye-catching products—the ones that make people stop and say "this changes everything." It does not reward incremental add-ons, no matter how well-executed. In an exponentially growing industry, the difference between alpha and beta plays is vast. The gap between the best product and everything else widens with each passing month.

In AI, either you are the best, or you are nothing. There's no comfortable middle ground. Companies that build foundational capabilities—training their own models, developing new architectures, creating novel interfaces—will capture the majority of value. Companies that add AI features to existing products will be left behind.

This is why Meta's approach matters. Building models from scratch, investing in infrastructure, and assembling top talent isn't just about competing—it's about having a chance to win. The alternative is watching from the sidelines as others define the future.

## Looking Forward

At Meta MSL, I'm part of a team that shares a vision for pushing the frontier of what's possible. We're asking fundamental questions about multimodal understanding, embodiment, and how AI systems interact with the world. We're building capabilities that don't exist yet, not just improving features that already do.

The work is challenging, but for the first time in a while, it feels like we're positioned to build something that matters—something that could be the best, not just good enough.

The AI field will continue to move fast. Companies that win will be those that combine strategic commitment, cultural urgency, and organizational alignment. But more than that, they'll be the ones building foundational capabilities rather than incremental features. Having experienced both environments, I've learned that the difference between shipping features and building the future comes down to this: are you training models and creating new capabilities, or are you adding AI to what already exists?

That's what I'm betting on. And for the first time in a while, it feels like the right bet.

## What This Means for Founders and Career Decisions

If you're building an AI startup or making a career transition, here's what I learned that might help:

**For founders: The alpha vs. beta play matters more in AI than in other industries.** I've advised startups and seen the difference: companies building foundational capabilities (training models, creating new architectures) capture value. Companies adding AI features to existing products get left behind. The market rewards first-movers who create eye-catching products, not incremental improvements. If you're starting an AI company, ask yourself: are you building something that doesn't exist yet, or are you adding AI to what already exists? The answer determines whether you're playing to win or playing to participate.

My work on JetMoE—reaching Llama2 performance with $0.1M—taught me that efficiency matters, but so does building something new. At Apple, I saw how incremental features (like notification summaries) shipped but didn't change the game. The companies that win in AI are building capabilities that don't exist yet, not improving features that already do.

**For career decisions: Look for strategic signals, not just role descriptions.** When I was deciding whether to leave Apple, I looked at three things: (1) What is the company actually doing, not what it says it's doing? Apple published "The Illusion of Thinking" and announced Liquid Glass—actions that signaled a shift away from AI. (2) Where is the industry heading, and where does this company want to be? Meta was going all-in on AGI; Apple was questioning whether AI works. (3) Does the culture match the ambition? At Apple, the culture was optimized for polish and stability; at Meta MSL, it's optimized for speed and exploration. The best career moves align with where the industry is heading, not where it is.

The signals I watched for: Are they publishing papers questioning AI or building AI that works? Are they investing in infrastructure (data centers, custom silicon) or cutting costs? Are they recruiting aggressively (like Meta's $200-300M packages) or slowing hiring? These aren't just company decisions—they're signals about strategic commitment.

**For evaluating opportunities: Capability and integration both matter, but most teams optimize for only one.** When I evaluate AI companies (as an advisor or for my own career), I look for teams that do both: push capability frontiers while also building integration systems. Apple had integration but wasn't pushing capability. Some research labs push capability but can't integrate. The teams that win do both. Ask: are they training models and building new capabilities, or are they adding AI to existing products? Are they building infrastructure to support their ambitions, or are they constrained by existing systems?

From my experience: At MIT-IBM Watson, I worked on pushing capability (synthetic data, code generation). At Apple, I learned integration (privacy, latency, organizational alignment). At Meta MSL, I'm seeing both—we're pushing capability frontiers while building systems that will turn research into product. That combination is what separates winners from participants.

**For timing: In an exponentially growing industry, the gap between leaders and followers widens fast.** I left Apple not because the work was bad, but because I saw the strategic shift happening. In AI, timing matters more than in slower-moving industries. The difference between joining a company that's going all-in versus one that's questioning the fundamentals compounds over time. If you're making a career move in AI, the question isn't just "is this a good role?" but "is this where the industry is heading, and do I want to be there when it arrives?"

The transition from Apple to Meta wasn't just about a better role—it was about positioning for where AI is heading. For founders building AI companies, or for anyone making career decisions in this field, the same principle applies: align with where the industry is going, not where it is.

---

*These are my own views, not those of Apple or Meta. I'm grateful for both experiences and the exceptional people I've worked with at each company. If you're building an AI startup or navigating a career transition in this field, I'm always open to conversations: [zguo0525@mit.edu](mailto:zguo0525@mit.edu).*

Liked this? Follow on X: [@Zhen4good](https://x.com/Zhen4good). Collaborations/advising: [zguo0525@mit.edu](mailto:zguo0525@mit.edu) • [LinkedIn](https://www.linkedin.com/in/gavin-guo-b764b6b4/)
